

# ğŸ“š Milestone 1 - RAG Document Ingestion Pipeline

This project implements the first milestone of a Retrieval-Augmented Generation (RAG) system.

The system loads documents (PDF + TXT), processes them into chunks, generates embeddings using a HuggingFace model, and stores them in a persistent Chroma vector database.

---

## ğŸš€ Features Implemented

âœ… Startup cleanup (Old Chroma DB deletion)  
âœ… Automatic directory scanning (Books folder)  
âœ… PDF loading using PyPDFLoader  
âœ… TXT loading using TextLoader  
âœ… Metadata cleaning before indexing  
âœ… Recursive chunking (chunk_size=3000, overlap=200)  
âœ… Local embedding generation using MiniLM  
âœ… Persistent vector storage using ChromaDB  

---

## ğŸ›  Tech Stack

- Python 3.11
- LangChain
- ChromaDB
- HuggingFace Embeddings
- Sentence Transformers
- dotenv (Environment variable management)

---


## ğŸ“‚ Project Structure

MILESTONE_ONE/
â”‚
â”œâ”€â”€ ingest.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Books/
â”‚   â”œâ”€â”€ cricket.txt
â”‚   â”œâ”€â”€ freedom_fighter_bhagat_singh.pdf
â”‚   â”œâ”€â”€ freedom_fighter_gandhi.pdf
â”‚   â””â”€â”€ freedom_fighter_rani_lakshmibai.pdf
â”‚
â”œâ”€â”€ chroma_db/  (generated)
â””â”€â”€ venv/       (ignored)

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate

2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

3ï¸âƒ£ Run the Ingestion Pipeline

python ingest.py

Expected Output:

Old chroma_db deleted successfully!
Total documents loaded: XX
Total chunks created: XX
Vector store created successfully!


---

ğŸ§  How It Works

1. Clears old vector database


2. Loads all supported documents from Books/


3. Cleans metadata


4. Splits documents into chunks


5. Generates embeddings using MiniLM


6. Stores embeddings in Chroma vector store




---

ğŸ¯ Milestone 1 Status

âœ” Document ingestion complete
âœ” Vector database creation complete
âœ” Embedding pipeline complete


